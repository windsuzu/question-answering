{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wikipedia as wiki\n",
    "from collections import OrderedDict\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiAnswerFinder:\n",
    "    def __init__(self, model_name=\"deepset/bert-base-cased-squad2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "        self.max_len = self.model.config.max_position_embeddings\n",
    "\n",
    "\n",
    "    def tokenize(self, question, context):\n",
    "        self.inputs = self.tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "        self.input_ids = self.inputs[\"input_ids\"].tolist()[0]\n",
    "        # print(f\"The tokenizer translates {len(text)} texts into {len(inputs['input_ids'][0])} tokens.\")\n",
    "        self.inputs = self.chunkify()\n",
    "\n",
    "\n",
    "    def chunkify(self):\n",
    "        qmask = self.inputs['token_type_ids'] < 1\n",
    "        qt = torch.masked_select(self.inputs['input_ids'], qmask)\n",
    "        # print(f\"The question consists of {qt.shape[0]} tokens.\")\n",
    "\n",
    "        chunk_size = self.max_len - qt.shape[0] - 1\n",
    "        # print(f\"Each chunk will contain {chunk_size - 2} tokens of the Wikipedia article.\")\n",
    "        # print(f\"Each Chunk size = [CLS] [question={qt.shape[0]}] [SEP] [context={chunk_size-2}] [SEP] = {max_size}\")\n",
    "\n",
    "        chunked_input = OrderedDict()\n",
    "\n",
    "        for k, v in self.inputs.items():\n",
    "            q = torch.masked_select(v, qmask)\n",
    "            c = torch.masked_select(v, ~qmask)\n",
    "            chunks = torch.split(c, chunk_size)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if i not in chunked_input: chunked_input[i] = {}\n",
    "                qc_pair = torch.cat((q, chunk))\n",
    "                if i != len(chunks) - 1:\n",
    "                    # append [SEP] to the end of (input_ids)\n",
    "                    # append 1 to the end of (attention_mask) or (token_type_ids)\n",
    "                    qc_pair = torch.cat((qc_pair, torch.tensor([102 if k == \"input_ids\" else 1])))\n",
    "                    \n",
    "                chunked_input[i][k] = torch.unsqueeze(qc_pair, dim=0)\n",
    "        return chunked_input\n",
    "\n",
    "\n",
    "    def get_answer(self, question):\n",
    "        results = wiki.search(question)\n",
    "        print(\"Question:\", question)\n",
    "        print(\"Wikipedia top search result:\", results[0])\n",
    "\n",
    "        page = wiki.page(results[0])\n",
    "        context = page.content\n",
    "        self.tokenize(question, context)\n",
    "\n",
    "        answer = \"\"\n",
    "        for _, chunk in self.inputs.items():\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(chunk[\"input_ids\"][0])\n",
    "            predicts = self.model(**chunk)\n",
    "            answer_start = torch.argmax(predicts.start_logits)\n",
    "            answer_end = torch.argmax(predicts.end_logits) + 1\n",
    "            chunk_answer = self.tokenizer.convert_tokens_to_string(tokens[answer_start:answer_end])\n",
    "\n",
    "            if not chunk_answer.startswith(\"[CLS]\"):\n",
    "                answer += chunk_answer + \" / \"\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = WikiAnswerFinder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the current president of Taiwan?\n",
      "Wikipedia top search result: President of the Republic of China\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3254 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tsai Ing - wen / Lai Ching - te / Donald Trump / Chiang Kai - shek / '"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.get_answer('Who is the current president of Taiwan?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the length of the Great Wall of China?\n",
      "Wikipedia top search result: Great Wall of China\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12, 000 mi ) / 6 mi ) / '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.get_answer('What is the length of the Great Wall of China?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the distance between the moon and the earth?\n",
      "Wikipedia top search result: Moon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.get_answer(\"What is the distance between the moon and the earth?\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f70d5b6488eff3ab7e6a6dbabbd0a5afcf1d1da8d76c577aa067863dcf1b32b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
